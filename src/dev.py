from functools import partial, wraps
import numpy as np
import jax
import jax.numpy as jnp
import jax.nn as jnn
import equinox as eqx
from flax import struct
from typing import Callable, NamedTuple
from jaxtyping import Array, Bool, Float, Int, PyTree

from src.cppn import CPPN, GraphCPPN
from src.substrate import SubstrateInitializer
from src.matching import intersection1d, optimal_match


State = tuple[Float[Array, "..."], PyTree, Float[Array, "..."], Int[Array, "..."], jax.Array]


#----------------------------- HyerCube Developmental Model ---------------------------------------

intersect_sorted_unique = partial(intersection1d, assume_unique=True, assume_ordered=True)
jit_unique = jax.jit(jnp.unique, static_argnames=['size'])


class FeedForwardPolicyParams(NamedTuple):
    nodes: PyTree
    weights: tuple[Float[Array, "I H"], Float[Array, "L H H"], Float[Array, "H O"]]
    biases: tuple[Float[Array, "I"], Float[Array, "L H"], Float[Array, "O"]]


class HyperCubeDevModel(eqx.Module):
    """
    Implements a developmental program using CPPNs and substrate initialization.

    As in the original ES-HyperNEAT version, this uses a CPPN to create a weight pattern from each
    input neuron. It then uses a substrate initializer to determine which hidden units should be
    active according to said pattern. The only requirements here are that former takes 6 inputs and
    returns a value and that latter can return position indices which can be used to determine the
    actual weights.

    Parameters
    ----------
    n_inputs: int
        The number of inputs in the policy network being developed.
    n_outputs: int
        The number of outputs in the policy network being developed.
    grid_size: tuple[int, int]
        The size of the grid pattern that is generated by the CPPN.
    cppn: CPPN
        The CPPN network used
    substrate: SubstrateInitializer
        The substrate initializer algorithm used.
    n_layers: int
        The number of hidden layers in the network.
    max_hidden:
        The maximum number of units per hidden layer to use. Defaults to the substrate's grid size
        since worst case scenario all potential cells are repated for each input.
    bounds: tuple
        Bounds of the substrate along each dimension: (x_min, x_max, y_min, y_max, z_min, z_max)
    """
    input_pos: list[tuple[float, float]]  # must be a tuple of lists for proper partitioning
    output_pos: list[tuple[float, float]]  # must be a tuple of lists for proper partitioning
    grid_size: tuple[int, int]
    n_layers: int
    max_hidden: int
    cppn: CPPN
    substrate: SubstrateInitializer
    weight_scale: float
    bounds: tuple[float, float, float, float, float, float]
    return_positions: bool

    def __init__(
        self,
        input_pos: list[tuple[float, float]] | int,
        output_pos: list[tuple[float, float]] | int,
        grid_size: int | tuple[int, int],
        cppn: CPPN,
        substrate: SubstrateInitializer,
        n_layers: int = 1,
        max_hidden: int | None = None,
        weight_scale: float = 0.1,
        bounds: tuple[Float, ...] | float | int = (-1, 1, -1, 1, -1, 1),
        return_positions: bool = False
    ):
        if isinstance(grid_size, int):
            grid_size = grid_size, grid_size

        if max_hidden is None:
            max_hidden = grid_size[0] * grid_size[1]

        if isinstance(input_pos, int):
            input_xs = tuple(float(x) for x in np.linspace(-1, 1, input_pos + 2)[1:-1])
            input_ys = tuple(float(x) for x in np.zeros((input_pos,)))
            input_pos = list(zip(input_xs, input_ys))

        if isinstance(output_pos, int):
            output_xs = tuple(float(x) for x in np.linspace(-1, 1, output_pos + 2)[1:-1])
            output_ys = tuple(float(x) for x in np.zeros((output_pos,)))
            output_pos = list(zip(output_xs, output_ys))

        if isinstance(bounds, (float, int)):
            bounds = abs(bounds)
            bounds = (-bounds, bounds, -bounds, bounds, -bounds, bounds)

        self.input_pos = input_pos  # type: ignore
        self.output_pos = output_pos  # type: ignore
        self.cppn = cppn
        self.grid_size = grid_size
        self.substrate = substrate
        self.n_layers = n_layers
        self.max_hidden = max_hidden
        self.weight_scale = weight_scale
        self.bounds = bounds
        self.return_positions = return_positions

    @property
    def inputs(self):
        inputs = np.asarray(self.input_pos)
        z_coord = -1 * np.ones((len(self.input_pos), 1))
        return np.concatenate([inputs, z_coord], axis=-1)

    @property
    def outputs(self):
        inputs = np.asarray(self.output_pos)
        z_coord = np.ones((len(self.output_pos),1))
        return np.concatenate([inputs, z_coord], axis=-1)

    @property
    def n_inputs(self):
        return self.inputs.shape[0]

    @property
    def n_outputs(self):
        return self.outputs.shape[0]

    def __call__(self, inputs, key: jax.Array = None):
        init_substrate = jax.vmap(self.init_substrate, in_axes=(0, None, None))
        per_output_constraints = jax.vmap(self.substrate_constraints, in_axes=(0, None))
        h2o_weight_fn = jax.vmap(jax.vmap(self.apply_cppn, in_axes=(None, 0)), in_axes=(0, None))

        # Determine the connectivity from the last layer backwards to use as a constraint
        # during the forward generative pass.
        def prune_ids(output_pos, layer_idx):
            ids = per_output_constraints(output_pos, layer_idx)
            ids = jit_unique(ids.ravel(), size=self.max_hidden, fill_value=self.max_hidden)
            pos = self.get_positions_at_layer(ids, layer_idx)
            return pos, ids

        # Run for the last layer separately as it has a differnt shape which makes it
        # incompatible with jax's scan function. Then run for the rest of the hidden layers.
        ho_topdown_pos, ho_constrain_ids = prune_ids(self.outputs, self.n_layers - 1)
        hn_constrain_ids = jax.lax.scan(
            prune_ids, ho_topdown_pos, jnp.arange(self.n_layers - 1), reverse=True
        )[1]
        # NOTE: No need to flip 'hn_constrain_ids', scan flips the result back when reverse=True.
        hn_constrain_ids = jnp.concatenate([hn_constrain_ids, ho_constrain_ids[None]])

        # Run the forward initialisation.
        def init_layer(input_positions, layer_idx):
            ids, W = init_substrate(input_positions, hn_constrain_ids[layer_idx], layer_idx)

            # Produce node ids
            # NOTE: We set unused node slots to max_hidden as this is the first out-of-bounds
            # index. This will cause take operations to discard the values and set them to
            # predefined ones that we can use as guards (e.g. inf).
            ids = jit_unique(ids.ravel(), size=self.max_hidden, fill_value=self.max_hidden)
            pos = self.get_positions_at_layer(ids, layer_idx)
            # Rearrange positions so that the weight matrices of subsequent layers are aligned.
            pos = jnp.full_like(pos, fill_value=jnp.inf).at[ids].set(
                pos, indices_are_sorted=True, unique_indices=True
            )

            bias = jax.vmap(self.apply_cppn)(pos, pos)
            bias = jnp.where(jnp.isnan(bias), 0.0, bias).squeeze()  # type: ignore

            info = pos if self.return_positions else ids

            return pos, (info, W, bias)

        # Same as before, first layer has different shape so run it separately. Then run the rest.
        h0_pos, (h0_info, W_ih, b_0) = init_layer(self.inputs, 0)
        h_pos, (h_info, W_hh, b_h) = jax.lax.scan(init_layer, h0_pos, jnp.arange(1, self.n_layers))

        # Initialise weights to the output units.
        W_ho = h2o_weight_fn(h_pos, self.outputs).squeeze(-1)
        W_ho = jnp.where(jnp.isnan(W_ho), 0.0, W_ho)  # set invalid weights to 0.0
        b_out = jax.vmap(self.apply_cppn)(self.outputs, self.outputs).squeeze(-1)

        node_info = self.collate_node_info(h0_info, h_info)

        return FeedForwardPolicyParams(node_info, (W_ih, W_hh, W_ho), (b_0, b_h, b_out))

    def substrate_constraints(self, output_pos, layer_idx):
        grid_points = self.substrate_positions(layer_idx).reshape(-1, 3)
        pattern = jax.vmap(self.apply_cppn, in_axes=(0, None))(grid_points, output_pos)
        node_grid_idx = self.substrate(pattern.reshape(*self.grid_size, 1))
        # Here node ids are the nodes connected to this output in the previous layer.
        return node_grid_idx[:, 0] * self.grid_size[0] + node_grid_idx[:, 1]

    def constrain_substrate(self, ff_ids, td_ids):
        return intersect_sorted_unique(
            ff_ids, td_ids, size=self.max_hidden, fill_value=self.max_hidden  # type: ignore
        )

    def init_substrate(
        self,
        inputs: Float[Array, "H 3"],
        contrain_ids: Int[Array, "H"],
        layer_idx: int,
    ) -> tuple[Int[Array, "H"], Float[Array, "H"]]:
        # Estimate pattern from input to substrate

        # NOTE: Because we use matrices of fixed max size, some inputs may correspond to unused
        # from the previous layer (i.e. with pos = inf). We just initialise their values to 0 and
        # their ids to invalid ones (i.e. id=max_hidden).
        def init_valid(inputs, constrain_ids, layer_idx):
            grid_points = self.substrate_positions(layer_idx).reshape(-1, 3)
            pattern = jax.vmap(self.apply_cppn, in_axes=(None, 0))(inputs, grid_points)
            node_grid_idx = self.substrate(pattern.reshape(*self.grid_size, 1))

            # Translate grid coordinates into raster index i.e. nodes indices are in [0, h * w],
            # with the final value corresponding to nodes that are not being used. This allows us
            # to use several conventions and optimization in jnp.take:
            #   - indices are sorted, leading to faster execution.
            #   - elements that are out of bounds will be dropped, and replaced with 'full_value'.
            # NOTE: it is important that unsed nodes have index h * w since we will use unique
            # again and we will get undefined behaviour if this is not the case.
            node_ids = node_grid_idx[:, 0] * self.grid_size[0] + node_grid_idx[:, 1]
            node_ids = intersect_sorted_unique(node_ids, constrain_ids)

            weights = jnp.take(pattern, node_ids, axis=0, fill_value=0, indices_are_sorted=True)
            weights = self.weight_scale * jnp.zeros((self.max_hidden,)).at[node_ids].set(
                weights.squeeze(), indices_are_sorted=True)

            return node_ids, weights

        def init_invalid(inputs, contrain_ids, layer_idx):  # type: ignore
            weights = jnp.zeros((self.max_hidden,))
            node_ids = jnp.full((self.max_hidden,), self.max_hidden)
            return node_ids, weights

        return jax.lax.cond(
            jnp.all(inputs < jnp.inf),
            init_valid,
            init_invalid,
            inputs, contrain_ids, layer_idx
        )

    def substrate_positions(self, layer_idx):  # type: ignore
        # Sample substrate positions in [1, 1], (-1, 1), i.e. excluding the endpoints for the z
        # coordinates as these are these endpoints are the locations of inputs and outputs.
        # TODO: REMOVE THE SLICING ON YS LATER.
        hidden_xs = jnp.linspace(*self.bounds[:2], self.grid_size[0])
        hidden_ys = jnp.linspace(*self.bounds[2:4], self.grid_size[1] + 2)[1:-1]
        hidden_zs = jnp.linspace(*self.bounds[4:], self.n_layers + 2)[1:-1][layer_idx][None]
        # NOTE: The output will be in Cartesian coordinates, meaning the output shape is reversed
        # with respect to the input. This is consistent with inputs to the CPPN being be (x, y).
        return jnp.concatenate(jnp.meshgrid(hidden_ys, hidden_xs, hidden_zs), axis=-1)

    def get_positions_at_layer(self, pos_idx, layer_idx):
        grid_points = self.substrate_positions(layer_idx).reshape(-1, 3)
        return jnp.take(grid_points, pos_idx, axis=0, fill_value=jnp.inf, indices_are_sorted=True)

    def apply_cppn(self, origin, target):
        io_pairs = jnp.concatenate([origin, target])
        return self.cppn(io_pairs)

    #-------------------------------- For visualising the network --------------------------------

    def collate_node_info(self, h0_info, h_info):
        input_info = self.get_in_node_info()
        output_info = self.get_out_node_info()
        h_info = jnp.concatenate([h0_info[None], h_info])
        return input_info, h_info, output_info

    def get_in_node_info(self):
        if self.return_positions:
            return self.inputs
        return jnp.arange(self.n_inputs)

    def get_out_node_info(self):
        if self.return_positions:
            return self.outputs
        layer_idxs = jnp.arange(self.max_hidden)
        return self.n_inputs + self.n_layers * self.max_hidden + layer_idxs


#----------------------------------- Policy Network + Development Model ---------------------------


class DevelopedFeedForwardPolicy(eqx.Module):
    dev_model: HyperCubeDevModel
    act_fn: Callable[[Float], Float]
    output_fn: Callable[[Float], Float]
    params_formatter: "NEATForwardPolicyShaper"

    def __init__(self, dev_model, act_fn=None, output_fn=None, params_formatter=None):
        super().__init__()

        if params_formatter is None:
            params_formatter = NEATForwardPolicyShaper()

        if output_fn is None:
            output_fn = lambda x: x

        if act_fn is None:
            act_fn = jax.nn.relu

        self.act_fn = act_fn
        self.output_fn = output_fn
        self.dev_model = dev_model
        self.params_formatter = params_formatter

    def __call__(
        self,
        inputs: tuple[Float[Array, "O"], FeedForwardPolicyParams],
        key: jax.Array | None = None
    ) -> Float[Array, "O"]:
        observations, policy_params = inputs
        _, (W_ih, W_hh, W_ho), (b_0, b_h, b_out) = policy_params

        def feeforward_step(h, i):
            h = jax.nn.relu(W_hh[i].T @ h + b_h[i])
            return h, None

        h = self.act_fn(W_ih.T @ observations + b_0)

        if len(W_hh) > 0:
            h = jax.lax.scan(feeforward_step, h, jnp.arange(len(W_hh)))[0]

        return self.output_fn(W_ho.T @ h + b_out)

    def init(self, inputs, key):
        return self.dev_model(inputs, key=key)

    def partition(self):
        params, statics = eqx.partition(self, eqx.is_array)
        params = self.params_formatter(params, statics)
        return params, statics

    def instantiate(self, params):
        params = self.params_formatter.reshape(params, self)
        return eqx.combine(self, params)



MAX_VAL = 2 ** 31 - 1

class NEATForwardPolicyShaper:
    def __call__(self, params, statics):
        return params

    def reshape(self, params, statics):
        topsort, genome_node, genome_conn, u_conn = params
        cppn = statics.dev_model.cppn
        N = len(genome_node)

        # last_idx = (topsort == MAX_VAL).argmax()
        # output_indics = jax.lax.dynamic_slice(topsort, [last_idx - n_outputs], [n_outputs])
        # swapped_ts = topsort.at[-n_outputs:].set(output_indics)
        # swapped_ts = swapped_ts.at[last_idx - n_outputs: last_idx].set(topsort[-n_outputs:])

        default_init = lambda x: jnp.where(jnp.isnan(x), 0, x)

        nodes = ~jnp.isnan(genome_node[:, 0])[topsort]
        bias = default_init(genome_node[:, 1])[topsort]

        # assume inputs and outputs are lined_up at the begining.
        act_fn = default_init(genome_node[:, 3].at[:cppn.n_inputs + cppn.n_outputs].set(0))
        # sort so that outputs are the last *used nodes*, we can use dynamic_slice to extract them
        act_fn = act_fn[topsort].astype(int)
        act_fn = jnp.where(act_fn == -1, 0, act_fn)  # default to first on the list if -1

        weights = jnp.take(genome_conn[:, -1], u_conn.reshape(-1)).reshape(N, N)
        weights = default_init(weights.T[topsort].T[topsort])

        params_paths = lambda t: (
            t.dev_model.cppn.nodes,
            t.dev_model.cppn.adjacency,
            t.dev_model.cppn.bias,
            t.dev_model.cppn.node_fn
        )

        return eqx.tree_at(
            params_paths, statics, (nodes, weights, bias, act_fn), is_leaf=lambda x: x is None
        )

